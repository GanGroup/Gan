\chapter{Introduction}

Generative Adversarial Networks (GANs) have emerged as a powerful class of generative models that revolutionize 
generative modeling by framing it as a game between two networks: a generator network that produces synthetic data 
from noise and a discriminator network that distinguishes between the generated data and real data \citep{10.48550/arxiv.1704.00028}. 
These networks, introduced in 2014, have found applications in various fields, including materials science, 
radiology, and computer vision \citep{10.1002/mgea.30}, \citep{10.1016/j.media.2019.101552}, \citep{10.1016/j.artmed.2020.101938}. 
For example, CycleGAN has been effectively applied in the medical field, notably in medical imaging tasks. 
It has enhanced liver lesion classification through GAN-based synthetic medical image augmentation, surpassing traditional data 
augmentation methods in sensitivity and specificity \citep{10.1016/j.neucom.2018.09.013}. 
Abdal et al. (2019) demonstrated the effectiveness of StyleGAN in tasks such as image deformation, style transfer \citep{10.1109/iccv.2019.00453}. 
GANs have gained significant attention in the computer vision community due to their ability to generate data without explicitly 
modeling the probability density function \citep{10.1016/j.media.2019.101552}.

The purpose of this paper is to gain a comprehensive understanding of Generative Adversarial Networks (GANs).
To achieve this, I will utilize the Animal Faces-HQ dataset, which comprises 16,130 high-quality images with a 
resolution of 512Ã—512 pixels, to train a standard GAN model specifically designed for generating realistic cat pictures.

The Structure of this thesis.

