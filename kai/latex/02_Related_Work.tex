\chapter{History Models of Image Generate}
\label{Related Work}

\section*{Deep Boltzmann Machines}

Deep Boltzmann Machines (DBMs) are complex multi-layer probabilistic generative models designed to capture intricate data distributions through an undirected network structure. The training process of DBMs is computationally intensive due to the utilization of Markov chains for estimating the model's probability distribution \citep{10.3390/a11040042}. This reliance on Markov chains can result in slow convergence, particularly with high-dimensional data, necessitating extensive sampling and iteration, leading to prolonged training times and stabilization challenges \citep{10.3390/a11040042}.

The intricacies of training DBMs not only affect computational efficiency but also impact the quality of generated samples. Consequently, DBMs have been somewhat overshadowed by more efficient models like Generative Adversarial Networks (GANs) and Variational Autoencoders (VAEs) \citep{10.1016/s0364-0213(85)80012-4}. GANs and VAEs offer superior training efficiency and generation capabilities compared to DBMs as they do not rely on Markov chains for training, thus overcoming the limitations associated with DBMs \citep{10.1016/s0364-0213(85)80012-4}.




\section*{Generative Stochastic Networks}

Generative machines have emerged as a solution to the challenges associated with training Deep Boltzmann Machines (DBMs) \citep{10.1093/imaiai/iaw003}. One notable example is Generative Stochastic Networks (GSNs), which have been developed to generate samples without explicitly representing the likelihood function. GSNs can be trained using exact backpropagation, eliminating the need for approximate methods required by DBMs. These networks are based on learning the transition operator of a Markov chain to estimate the data distribution. Furthermore, the concept of generative machines has been extended by eliminating Markov chains in generative stochastic networks, enhancing their efficiency and effectiveness \citep{10.48550/arxiv.2302.09465}.

Generative Neurosymbolic Machines represent another advancement in generative models, combining distributed and symbolic representations to support structured symbolic components and density-based generation. This approach leverages the benefits of both types of representations to enhance the overall performance of generative models.

In summary, generative machines like GSNs and Generative Neurosymbolic Machines offer innovative solutions for generating samples without explicitly modeling the likelihood function, thereby overcoming the complexities associated with training DBMs. These advancements in generative models pave the way for more efficient and effective sample generation in machine learning applications.



\section*{Variational Autoencoders}


Variational Autoencoders (VAEs) have gained significant attention in the field of deep learning due to their ability to learn latent representations of complex data. Kingma and Welling, along with Rezende et al., introduced a stochastic back-propagation rule that enables training VAEs by back-propagation through a Gaussian distribution \citep{10.48550/arxiv.1909.13062}. This approach pairs a generative network with a discriminative model to perform approximate inference, allowing VAEs to learn to encode data into a low-dimensional latent space and decode it back to the original data \citep{10.3390/bioengineering10101209}.

However, VAEs face limitations in modeling discrete data as they require back-propagation through hidden units, which poses challenges in handling such data types effectively \citep{10.48550/arxiv.1909.13062}. Despite this limitation, VAEs have been extensively used to represent high-dimensional complex data by learning a low-dimensional latent space in an unsupervised manner \citep{10.48550/arxiv.2106.06500}.

In summary, VAEs offer a powerful framework for deep generative modeling, enabling the creation of latent representations of data that can be decoded back to the original form. While they excel in modeling continuous data, challenges persist in effectively modeling discrete data due to the nature of back-propagation through hidden units.


\section*{Generative Stochastic Networks}


Noise Contrastive Estimation (NCE) is a technique used in training generative models by distinguishing between data and noise samples \citep{10.21437/interspeech.2016-1295}. It has been applied in various fields such as speech recognition and language modeling due to its ability to handle large vocabularies efficiently \citep{10.1609/aaai.v32i1.11967}. NCE addresses the computational challenges posed by traditional methods like softmax by transforming the estimation problem into a binary classification task \citep{10.18653/v1/e17-2003}. By discriminating between observed data and artificially generated noise, NCE enables the estimation of non-normalized models effectively \citep{10.48550/arxiv.1805.07516}.

One of the key limitations of NCE is the need to evaluate and backpropagate two probability densities, one for the noise distribution and the other for the model distribution \citep{10.18653/v1/e17-2003}. Despite this limitation, NCE has proven to be a highly effective approach for unsupervised representation learning using deep networks \citep{10.48550/arxiv.2205.01789}. The method has also been extended to flow models for energy-based models, where the update is based on noise contrastive estimation \citep{10.1109/cvpr42600.2020.00754}.

In the context of training large vocabulary neural language models, NCE has been shown to be a sampling-based technique that offers speed improvements \citep{10.18653/v1/p16-1186}. Researchers have explored different strategies to enhance the training algorithms, including investigating noise contrastive estimation and diagonal contexts for further speed improvements \citep{10.3115/v1/n15-1083}. Additionally, the use of noise-contrastive estimation has been linked to self-supervised tasks in state-of-the-art methods \citep{10.48550/arxiv.2203.01110}.

In conclusion, Noise Contrastive Estimation (NCE) is a valuable technique for training generative models efficiently, particularly in scenarios with large vocabularies. While it has some limitations related to the evaluation of multiple probability densities, researchers continue to explore and extend NCE to address various challenges in unsupervised representation learning.


\section*{Predictability minimization}

Machine learning method for GAN



Predictability minimization is a technique that involves training two neural networks competitively to encourage the hidden units of the neural network to be independent of each other. Unlike Generative Adversarial Networks (GANs), where the competition is the sole training criterion, predictability minimization uses a regularizer to promote independence among the hidden units \citep{10.1145/2640087.2644155}.

In the context of predictive coding, predictability minimization aims to reduce prediction errors by minimizing the mismatch between incoming sensations and predictions established through experience. This process involves deviance processing, which is part of an inference process where prediction errors are minimized at different levels of the auditory hierarchy \citep{10.3389/fnhum.2015.00505}.

Regularization techniques play a crucial role in predictability minimization by penalizing model complexity to prevent overfitting. These methods typically involve balancing prediction errors on training data against regularization to optimize the model's performance \citep{10.1186/1471-2105-16-s16-s2}. Regularization functions often impose constraints on the model to ensure smooth transitions and prevent over-parameterization, thus aiding in minimizing prediction errors \citep{10.1007/978-1-4615-5339-7_102}.

Overall, predictability minimization, through the use of regularization techniques and competitive training of neural networks, aims to enhance the independence of hidden units and reduce prediction errors by optimizing model complexity and promoting smoother transitions within the model.


