\chapter{Theoretical Background}
\label{Theoretical Background for GAN}
This chapter covers the theoretical foundations of Generative Adversarial Networks (GANs),
including their objective function, the training dynamics between the generator and discriminator, 
and the use of metrics like Fréchet Inception Distance (FID) to evaluate performance. 



\section{Objective Function of GAN}

Generative Adversarial Networks (GANs) consist of a generator G and a discriminator D, 
both implemented using artificial neural networks. The parametrization of GANs involves 
defining the network structure of these components and initializing their weights and biases \citep{10.1007/s10928-021-09787-4}. 
The success of GANs relies on balancing the training of these two networks, where the 
G aims to produce samples $G(z)$ that mimic real data distributions $p_{data}(x)$ by input noise z, while the D 
learns to differentiate between real and generated samples \citep{10.1109/taslp.2017.2761547}. 
The training process involves iteratively updating the weights and biases of the networks through 
adversarial training, where the generator tries to deceive the discriminator, and the discriminator 
aims to accurately classify samples \citep{10.48550/arxiv.1802.05637}.
The objective function for GAN has the following form:


\begin{equation}
    \label{eq:min & max}
    % \min_{G} \max_{D} V(D, G) = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_{z}(z)} [\log(1 - D(G(z)))].
    V(D, G) = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_{z}(z)} [\log(1 - D(G(z)))].
\end{equation}



It describes the game process between the Generator (G) and the Discriminator (D). Specifically, 
the formula defines a minimax game between the Discriminator and the Generator.

\begin{itemize}
    \item \textbf{ $z \sim p_{z}(z)$} represents the distribution from which the noise $z$ is sampled. 
    The purpose of using a noise distribution is to provide random input for the generator, which transforms 
    this noise into more complex, high-dimensional data.
    
    Example: If we assume $ p_z(z) = \mathcal{N}(0, 1) $, then $z$ could be a vector of random values sampled independently from $ \mathcal{N}(0, 1) $. The generator would then take this random vector $z$ and map it to a synthetic image, such as a cat image, that resembles data from the real world.
    \item \textbf{ $x \sim p_{data}(x)$} represent that sample x is drawn from the true data distribution $p_{data}$.
    \item \textbf{ $D(G(z))$} represent the output of the discriminator for the data $G(z)$ generated by 
    the generator. Indicating the probability that the discriminator believes that the generated 
    data comes from the real data distribution.
    \item \textbf{$D(x)$} represent the output of the discriminator for the real data x. Indicating the probability that 
    the discriminator believes that the real data x comes from the real data distribution.
    \item \textbf{$\mathbb{E}{_x \sim p_{data}(x)}[\log D(x)]$} represent the average value of $\log D(x)$ 
    for all samples x on the true data distribution $p_{data}(x)$.
    \item \textbf{$\mathbb{E}{x \sim p_{z}(z)}[\log (1 - D(x))]$} represent the average value of $\log (1 - D(G(z)))$ 
    for all samples z on the noise distribution $p_z(z)$.
\end{itemize}


The following formulas:

\begin{equation}
    \label{eq:max}
    \max_{D} V(D, G) = \mathbb{E}_{x \sim p_{data}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_{z}(z)} [\log(1 - D(G(z)))].
\end{equation}

\begin{equation}
    \label{eq:min}
    \min_{G} V(G) = \mathbb{E}_{z \sim p_{z}(z)} [\log(1 - D(G(z)))].
\end{equation}

explains the continuous balance between the generator and discriminator. 
As the generator improves its ability to create more realistic data, 
the discriminator adjusts to better distinguish real data from generated data. 
This interaction drives the GAN model to produce outputs that resemble real data more closely.

 
The formula \eqref{eq:max} explains the goal of the discriminator, which is to maximize the value of $V(D, G)$. The first component measures how 
likely the discriminator is to accurately identify real data, while the second component reflects the discriminator’s 
ability to correctly recognize generated data as fake. Conversely, the generator’s objective is to minimize $V(D, G)$ 
by producing data that makes the second term larger, aiming to trick the discriminator into believing the generated data is genuine.


The formula \eqref{eq:min} shows the generator tries to minimize $V(G)$. 
This means that the generator tries to generate realistic data $G(z)$ so that the discriminator cannot distinguish 
them from real data. 

In real training process, the formula \eqref{eq:min} will replace by \eqref{eq:new min}:
\begin{equation}
    \label{eq:new min}
    \min_{G} V(D, G) = \mathbb{E}_{z \sim p_{z}(z)} [-\log(D(G(z)))].
\end{equation}

The reason for replacing $\log(1 - D(G(z)))$ with $-\log(D(G(z)))$ in practice is to address the vanishing 
gradient problem. As seen in the figure \ref{fig:log_function}, $\log(1 - D)$ (blue curve) rapidly decays towards negative infinity 
when $D$ approaches 1, resulting in very small gradients for the generator when the discriminator is strong. 
This significantly slows down the generator's learning process. In contrast, $-\log(D)$ (red curve) provides 
larger gradients even when $D$ is close to 0, allowing the generator to continue learning effectively even 
against a strong discriminator. Therefore, the modified formula ensures that the generator receives significant 
gradient updates and avoids stagnation during training.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{./Images/log_gunction.jpg}
    \caption{Comparison of $\log(1 - D)$ and $-\log(D)$.}
    \label{fig:log_function}
\end{figure}


The GAN network parameters play a crucial role in determining the quality and diversity of 
the generated samples $G(x)$ \citep{10.1007/s10928-021-09787-4}. The optimization process in GANs is a min-max game. 
The generator aims to minimize the loss function, attempting to generate data that can fool the discriminator, while 
the discriminator aims to maximize its ability to correctly classify real and generated data. This min-max dynamic 
is critical for balancing the training of both networks. \citep{10.1109/taslp.2017.2761547}. Maintaining this balance 
during training is essential for achieving high-quality sample generation \citep{10.1007/s10928-021-09787-4}. 
The $D$'s role is to provide feedback to the generator by acting as a critic, 
guiding the $G$ towards producing more realistic samples \citep{10.48550/arxiv.1802.05637}.



\section{Training Process of GAN}

The training process of Generative Adversarial Networks (GANs) is inherently adversarial. 
The generator endeavors to create increasingly realistic fake samples to deceive the discriminator, 
while the discriminator seeks to more accurately distinguish between real and fake samples. 
To understand how this process works, in the following sections, 
I will describe the GAN training process from the perspectives of data distribution and mathematical formulation.

\subsection{Distribution Changes During GAN Training}
A simaple diagram show how distribution change in GAN training.

\begin{figure}[h]
    \centering
    \includegraphics[width=1.2\linewidth]{./Images/data_distribution.jpg}
    \caption{ Diagram of GAN's training process. 
    The green curve represents the distribution of generated samples. Initially, the generated samples may differ significantly from the real samples. As training progresses, the generated samples' distribution gradually approaches the real samples.
    The black dots represent the distribution of real samples, which remains unchanged throughout the training process and represents the target distribution.
    The blue dashed line represents the discriminator's output probability distribution. At the beginning of training, the discriminator can easily distinguish between real and generated data, resulting in a strong classification boundary. As training progresses and the generated data becomes more realistic, the discriminator's ability to differentiate between the two distributions weakens. Eventually, the discriminator's output approaches 0.5, indicating it can no longer effectively distinguish between real and generated data.
    The lines labeled $x$ and $z$ below represent the distribution of samples in the latent space. During GAN training, samples from the latent space $z$ are mapped to the data space $x$ through the generator.
    }
    \label{fig:gan_training_process}
    \vspace{1pt} % Vertical space, optional
    \small{Source: \cite{goodfellow2014generative}}
\end{figure}

During the training process of the GAN model, the generator and the discriminator fight against each other. 
The generator tries to produce realistic samples to fool the discriminator, while the discriminator strives 
to distinguish real samples from generated samples. Initially, the generator generates samples with poor 
quality and large errors, similar to the blue sine wave in Figure (a). However, as training proceeds and 
the generator continues to improve, the error in generated samples gradually decreases, similar to the 
blue lines in figures (b) and (c) becoming flat. At the same time, the distribution of real samples and 
generated samples gradually becomes consistent, and finally reaches the optimal state in Figure (d). At this moment $p_{data}(x) = p_g(x)$, 
the samples generated by the generator are almost the same as the real samples, and the error is minimized. 
During the entire process, the sample distribution gradually converges from the initial noise and discrete 
state to a state that highly coincides with the real distribution, reflecting a significant improvement in 
the quality of the generated samples.


\subsection{Mathematical Formulation Changes During GAN Training}


1. Problem Setup

In a Generative Adversarial Network (GAN), the objective is to train a generator \( G \) and a discriminator \( D \) 
to generate data that resembles the real data distribution. The objective function to be maximized is given by:

\begin{equation}
    V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}(x)} [\log D(x)] + \mathbb{E}_{z \sim p_{z}(z)} [\log (1 - D(G(z)))].
\end{equation}

2. Rewriting the Objective Function

First, the objective function is rewritten in integral form:

\begin{equation}
    V(D, G) = \int p_{\text{data}}(x) \log D(x) \, dx + \int p_{z}(z) \log (1 - D(G(z))) \, dz.
\end{equation}

By changing variables $x' = G(z)$, the generated data is represented as $x'$, which corresponds to samples produced by the generator $G$. This allows the second term to be rewritten as an integral over the generated data distribution $p_g(x)$. The integral now reflects the contribution of the generated samples to the objective function.

\begin{equation}
    \int p_g(x) \log (1 - D(x)) \, dx.
\end{equation}

Thus, the objective function becomes:

\begin{equation}
    V(D, G) = \int \left[ p_{\text{data}}(x) \log D(x) + p_g(x) \log (1 - D(x)) \right] dx.
\end{equation}

3. Deriving the Optimal Discriminator

To find the optimal discriminator \( D^* \), it needs to take the derivative of the objective function with respect to \( D(x) \) and set it to zero.

Let:

\begin{equation}
    f(D(x)) = p_{\text{data}}(x) \log D(x) + p_g(x) \log (1 - D(x)).
\end{equation}

Taking the derivative with respect to \( D(x) \):

\begin{equation}
    \frac{d}{dD(x)} f(D(x)) = \frac{p_{\text{data}}(x)}{D(x)} - \frac{p_g(x)}{1 - D(x)}.
\end{equation}

Setting the derivative to zero:

\begin{equation}
    \frac{p_{\text{data}}(x)}{D(x)} = \frac{p_g(x)}{1 - D(x)}
    \label{eq:derivative_to_zero}
\end{equation}

Solving equation \eqref{eq:derivative_to_zero}:

\begin{equation}
    D(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
\end{equation}

4. Optimal Discriminator Formula

Therefore, the optimal discriminator \( D^* \) is given by:

\begin{equation}
    D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
\end{equation}


\begin{itemize}
    \item When $p_{\text{data}}(x)$ is much larger than $p_g(x)$, $D^*(x) \approx 1$, indicating that the data point is almost certainly from the real data.
    
    \item When $p_{\text{data}}(x)$ is much smaller than $p_g(x)$, $D^*(x) \approx 0$, indicating that the data point is almost certainly from the generated data.
    
    \item When $p_{\text{data}}(x)$ is close to $p_g(x)$, $D^*(x) \approx 0.5$, indicating that the discriminator cannot confidently determine whether the data point is real or generated, giving each a 50\% probability.
\end{itemize}

5. Verifying the Optimal Discriminator

To verify that this \( D^* \) maximizes the objective function, substitute \( D^* \) back into the objective function:

\begin{equation}
    V(D^*, G) = \int \left[ p_{\text{data}}(x) \log \left( \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} \right) + p_g(x) \log \left( 1 - \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} \right) \right] dx.
\end{equation}

Since:

\begin{equation}
    1 - D^*(x) = 1 - \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} = \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)},
\end{equation}

substituting this in:

\begin{equation}
    V(D^*, G) = \int \left[ p_{\text{data}}(x) \log \left( \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)} \right) + p_g(x) \log \left( \frac{p_g(x)}{p_{\text{data}}(x) + p_g(x)} \right) \right] dx.
\end{equation}

This objective function represents the negative of the cross-entropy, which is maximized when $D(x) = D^*(x)$. When $D(x) = 0.5$, the discriminator cannot distinguish between real and generated data, indicating that the generator has produced samples that closely resemble the real data. Maximizing the negative cross-entropy aligns the generated data distribution with the real data distribution.

6. Conclusion

Through the above derivation, it has shown that given the generator \( G \), the optimal form of the discriminator \( D \) is:

\begin{equation}
    D^*(x) = \frac{p_{\text{data}}(x)}{p_{\text{data}}(x) + p_g(x)}.
\end{equation}

This demonstrates that the optimal discriminator \( D^* \) outputs the probability that the input data comes from the 
real data distribution. 
This formula provides a theoretical foundation for training GANs, guiding the updates to the generator \( G \) so that 
its generated data gradually approaches the real data distribution.


\section{Evaluating GAN Performance}


Fréchet Inception Distance (FID) is a metric commonly used in Generative Adversarial Network (GAN) models 
to quantify the dissimilarity between two image distributions \citep{10.48550/arxiv.2203.06026}. 
It measures the distance between the distributions of real images and generated images, providing 
a numerical assessment of the quality of generated images. FID has gained prominence in evaluating 
the performance of GANs due to its ability to capture both the quality and diversity of generated images \citep{10.3390/app12157599}.
The following is the objective function for FID:


\begin{equation}
    \text{FID} = || \mu_r - \mu_g ||^2 + \text{Tr}(\Sigma_r + \Sigma_g - 2(\Sigma_r \Sigma_g)^{1/2})
\end{equation}


\begin{equation}
    \mu_r = \frac{1}{N} \sum_{i=1}^{N} f(x_i), \quad \Sigma_r = \frac{1}{N} \sum_{i=1}^{N} (f(x_i) - \mu_r)(f(x_i) - \mu_r)^T
\end{equation}

\begin{equation}
    \mu_g = \frac{1}{M} \sum_{i=1}^{M} f(G(z_i)), \quad \Sigma_g = \frac{1}{M} \sum_{i=1}^{M} (f(G(z_i)) - \mu_g)(f(G(z_i)) - \mu_g)^T
\end{equation}


\begin{itemize}
    \item $\mu_r \text{ and } \mu_g$ represent the feature means of the real and generated images, respectively.
    \item $\Sigma_r \text{ and } \Sigma_g$ represent the feature covariance matrices of the real and generated images, respectively.
    \item $\text{Tr}$ represents the trace (the sum of the diagonal elements of the matrix).
    \item $f$ represents the feature extraction function, which extracts feature vectors from images using the Inception network. These feature vectors are used to compute the mean and covariance for both real and generated images.
\end{itemize}


A lower FID value indicates that the distribution of the generated images is closer to that of real images, 
reflecting higher quality and diversity in the generated images \citep{10.1117/12.2673366}. 
Specifically, a FID value below 10 is considered to represent very high-quality generated images, 
while values between 10 and 50 indicate good quality, and values above 50 suggest average or poor quality \citep{10.1117/12.2673366}.



\section{Limitations of Accuracy in Evaluating GANs}
Accuracy is not suitable for evaluating GANs because accuracy is an indicator of classification tasks, 
which is used to measure the prediction accuracy of the model in classification tasks, and cannot 
measure the quality and diversity of generated data. In generation tasks, there is no clear 
"correct answer" and the generated data has no "real label", so it is impossible to directly 
compare the correspondence between the generated data and a real sample. 

The following is a result for a standard GANs model with high accuracy but generate low quality images.


\begin{figure}[H]
    \centering
    \includegraphics[width=1.2\linewidth]{./Images/model_accuracy.jpg}
    \caption{GAN Training Accuracy Over Epochs}
    \label{fig:my_picture}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=1.2\linewidth]{./Images/generate_images.jpg}
    \caption{Generated Images from GAN}
    \label{fig:my_picture}
\end{figure}


FID (Fréchet Inception Distance) quantifies the difference between generated data and real 
data by comparing their distribution in the Inception network feature space. FID takes into 
account the overall distribution of generated data and real data, and can reflect the quality 
and diversity of generated data. A low FID value indicates that the distribution of generated 
data is very close to the distribution of real data, that is, the generated data is both realistic 
and diverse, so FID is a more suitable indicator for evaluating the performance of generative models.