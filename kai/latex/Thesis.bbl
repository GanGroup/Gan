\begin{thebibliography}{10}

\bibitem{10.48550/arxiv.1704.00028}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~Courville.
\newblock Improved training of wasserstein gans.
\newblock 2017.

\bibitem{10.1002/mgea.30}
Y.~Jiang.
\newblock Applications of generative adversarial networks in materials science.
\newblock {\em Materials Genome Engineering Advances}, 2, 2024.

\bibitem{10.1016/j.media.2019.101552}
Y.~Xin, E.~Walia, and P.~Babyn.
\newblock Generative adversarial network in medical imaging: a review.
\newblock {\em Medical Image Analysis}, 58:101552, 2019.

\bibitem{10.1016/j.artmed.2020.101938}
S.~Kazeminia, C.~Baur, A.~Kuijper, B.~Ginneken, N.~Navab, S.~Albarqouni, and A.~Mukhopadhyay.
\newblock Gans for medical image analysis.
\newblock {\em Artificial Intelligence in Medicine}, 109:101938, 2020.

\bibitem{10.1016/j.neucom.2018.09.013}
M.~Frid-Adar, I.~Diamant, E.~Klang, M.~M. Amitai, J.~Goldberger, and H.~Greenspan.
\newblock Gan-based synthetic medical image augmentation for increased cnn performance in liver lesion classification.
\newblock {\em Neurocomputing}, 321:321--331, 2018.

\bibitem{10.1109/iccv.2019.00453}
R.~Abdal, Y.~Qin, and P.~Wonka.
\newblock Image2stylegan: how to embed images into the stylegan latent space?
\newblock {\em 2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 2019.

\bibitem{10.48550/arxiv.1603.06170}
H.~Xu and Z.~Ou.
\newblock Joint stochastic approximation learning of helmholtz machines.
\newblock 2016.

\bibitem{10.1109/access.2014.2319813}
K.~Zhang and X.~Chen.
\newblock Large-scale deep belief nets with mapreduce.
\newblock {\em Ieee Access}, 2:395--403, 2014.

\bibitem{10.48550/arxiv.1410.0123}
G.~Desjardins.
\newblock Deep tempering.
\newblock 2014.

\bibitem{10.48550/arxiv.1406.2751}
J.~Bornschein.
\newblock Reweighted wake-sleep.
\newblock 2014.

\bibitem{10.48550/arxiv.1311.1354}
J.~Melchior.
\newblock How to center binary deep boltzmann machines.
\newblock 2013.

\bibitem{10.7566/jpsj.85.034001}
C.~Takahashi and M.~Yasuda.
\newblock Mean-field inference in gaussian restricted boltzmann machine.
\newblock {\em Journal of the Physical Society of Japan}, 85:034001, 2016.

\bibitem{10.1093/imaiai/iaw003}
G.~Alain, Y.~Bengio, L.~Yao, J.~Yosinski, É. Thibodeau-Laufer, S.~Zhang, and P.~Vincent.
\newblock Gsns: generative stochastic networks.
\newblock {\em Information and Inference a Journal of the Ima}, 5:210--249, 2016.

\bibitem{10.48550/arxiv.2302.09465}
L.~Pan, D.~Zhang, J.~Moksh, L.~Huang, and Y.~Bengio.
\newblock Stochastic generative flow networks.
\newblock 2023.

\bibitem{10.48550/arxiv.1909.13062}
P.~Munjal, A.~Paul, and N.~Krishnan.
\newblock Implicit discriminator in variational autoencoder.
\newblock 2019.

\bibitem{10.3390/bioengineering10101209}
M.~Sidulova.
\newblock Conditional variational autoencoder for functional connectivity analysis of autism spectrum disorder functional magnetic resonance imaging data: a comparative study.
\newblock {\em Bioengineering}, 10:1209, 2023.

\bibitem{10.48550/arxiv.2106.06500}
X.~Bie, L.~Girin, S.~Leglaive, T.~Hueber, and X.~Alameda-Pineda.
\newblock A benchmark of dynamical variational autoencoders applied to speech spectrogram modeling.
\newblock 2021.

\bibitem{10.21437/interspeech.2016-1295}
B.~Damavandi, S.~Kumar, N.~Shazeer, and A.~Bruguier.
\newblock Nn-grams: unifying neural network and n-gram language models for speech recognition.
\newblock 2016.

\bibitem{10.1609/aaai.v32i1.11967}
F.~Liza and M.~Grzes.
\newblock Improving language modelling with noise contrastive estimation.
\newblock {\em Proceedings of the Aaai Conference on Artificial Intelligence}, 32, 2018.

\bibitem{10.18653/v1/e17-2003}
M.~Labeau and A.~Allauzen.
\newblock An experimental analysis of noise-contrastive estimation: the noise distribution matters.
\newblock 2017.

\bibitem{10.48550/arxiv.1805.07516}
T.~Matsuda and A.~Hyvärinen.
\newblock Estimation of non-normalized mixture models and clustering using deep representation.
\newblock 2018.

\bibitem{10.48550/arxiv.2205.01789}
P.~Awasthi, N.~Dikkala, and P.~Kamath.
\newblock Do more negative samples necessarily hurt in contrastive learning?
\newblock 2022.

\bibitem{10.1109/cvpr42600.2020.00754}
R.~Gao, E.~Nijkamp, D.~Kingma, Z.~Xu, A.~Dai, and Y.~Wu.
\newblock Flow contrastive estimation of energy-based models.
\newblock 2020.

\bibitem{10.18653/v1/p16-1186}
W.~Chen, D.~Grangier, and M.~Auli.
\newblock Strategies for training large vocabulary neural language models.
\newblock 2016.

\bibitem{10.3115/v1/n15-1083}
P.~Baltescu and P.~Blunsom.
\newblock Pragmatic neural language modelling in machine translation.
\newblock 2015.

\bibitem{10.48550/arxiv.2203.01110}
O.~Chehab, A.~Gramfort, and A.~Hyvärinen.
\newblock The optimal noise in noise-contrastive learning is not what you think.
\newblock 2022.

\bibitem{10.1145/2640087.2644155}
M.~Li.
\newblock Scaling distributed machine learning with the parameter server.
\newblock 2014.

\bibitem{10.3389/fnhum.2015.00505}
F.~Lecaignard, O.~Bertrand, G.~Gimenez, J.~Mattout, and A.~Caclin.
\newblock Implicit learning of predictable sound sequences modulates human brain responses at different levels of the auditory hierarchy.
\newblock {\em Frontiers in Human Neuroscience}, 9, 2015.

\bibitem{10.1186/1471-2105-16-s16-s2}
H.~Liu, K.~Verspoor, D.~Comeau, A.~MacKinlay, and W.~Wilbur.
\newblock Optimizing graph-based patterns to extract biomedical events from the literature.
\newblock {\em BMC Bioinformatics}, 16, 2015.

\bibitem{10.1007/978-1-4615-5339-7_102}
B.~Wang, J.~Basart, and J.~Moulder.
\newblock Linear and nonlinear image restoration methods for eddy current nondestructive evaluation.
\newblock pages 791--798, 1998.

\bibitem{10.1007/s10928-021-09787-4}
J.~Parikh, T.~Rumbell, X.~Butova, T.~Myachina, J.~Acero, S.~Khamzin, O.~Solovyova, J.~Kozloski, A.~Khokhlova, and V.~Gurev.
\newblock Generative adversarial networks for construction of virtual populations of mechanistic models: simulations to study omecamtiv mecarbil action.
\newblock {\em Journal of Pharmacokinetics and Pharmacodynamics}, 49:51--64, 2021.

\bibitem{10.1109/taslp.2017.2761547}
Y.~Saito, S.~Takamichi, and H.~Saruwatari.
\newblock Statistical parametric speech synthesis incorporating generative adversarial networks.
\newblock {\em Ieee/Acm Transactions on Audio Speech and Language Processing}, 26:84--96, 2018.

\bibitem{10.48550/arxiv.1802.05637}
T.~Miyato.
\newblock Cgans with projection discriminator.
\newblock 2018.

\bibitem{10.48550/arxiv.1908.05861}
A.~Lahiri.
\newblock The angel is in the priors: improving gan based image and sequence inpainting with better noise and structural priors.
\newblock 2019.

\bibitem{10.1002/mp.14062}
X.~Tie, S.~Lam, Y.~Zhang, K.~Lee, K.~Au, and J.~Cai.
\newblock Pseudo‐ct generation from multi‐parametric mri using a novel multi‐channel multi‐path conditional generative adversarial network for nasopharyngeal carcinoma patients.
\newblock {\em Medical Physics}, 47:1750--1762, 2020.

\end{thebibliography}
