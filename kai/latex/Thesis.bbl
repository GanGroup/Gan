\begin{thebibliography}{10}

\bibitem{10.48550/arxiv.1704.00028}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~Courville.
\newblock Improved training of wasserstein gans.
\newblock 2017.

\bibitem{10.1002/mgea.30}
Y.~Jiang.
\newblock Applications of generative adversarial networks in materials science.
\newblock {\em Materials Genome Engineering Advances}, 2, 2024.

\bibitem{10.1016/j.media.2019.101552}
Y.~Xin, E.~Walia, and P.~Babyn.
\newblock Generative adversarial network in medical imaging: a review.
\newblock {\em Medical Image Analysis}, 58:101552, 2019.

\bibitem{10.1016/j.artmed.2020.101938}
S.~Kazeminia, C.~Baur, A.~Kuijper, B.~Ginneken, N.~Navab, S.~Albarqouni, and A.~Mukhopadhyay.
\newblock Gans for medical image analysis.
\newblock {\em Artificial Intelligence in Medicine}, 109:101938, 2020.

\bibitem{10.1016/j.neucom.2018.09.013}
M.~Frid-Adar, I.~Diamant, E.~Klang, M.~M. Amitai, J.~Goldberger, and H.~Greenspan.
\newblock Gan-based synthetic medical image augmentation for increased cnn performance in liver lesion classification.
\newblock {\em Neurocomputing}, 321:321--331, 2018.

\bibitem{10.1109/iccv.2019.00453}
R.~Abdal, Y.~Qin, and P.~Wonka.
\newblock Image2stylegan: how to embed images into the stylegan latent space?
\newblock {\em 2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 2019.

\bibitem{10.3390/a11040042}
M.~Yasuda.
\newblock Learning algorithm of boltzmann machine based on spatial monte carlo integration method.
\newblock {\em Algorithms}, 11:42, 2018.

\bibitem{10.1016/s0364-0213(85)80012-4}
D.~Ackley, G.~Hinton, and T.~Sejnowski.
\newblock A learning algorithm for boltzmann machines.
\newblock {\em Cognitive Science}, 9:147--169, 1985.

\bibitem{10.1093/imaiai/iaw003}
G.~Alain, Y.~Bengio, L.~Yao, J.~Yosinski, É. Thibodeau-Laufer, S.~Zhang, and P.~Vincent.
\newblock Gsns: generative stochastic networks.
\newblock {\em Information and Inference a Journal of the Ima}, 5:210--249, 2016.

\bibitem{10.48550/arxiv.2302.09465}
L.~Pan, D.~Zhang, J.~Moksh, L.~Huang, and Y.~Bengio.
\newblock Stochastic generative flow networks.
\newblock 2023.

\bibitem{10.48550/arxiv.1909.13062}
P.~Munjal, A.~Paul, and N.~Krishnan.
\newblock Implicit discriminator in variational autoencoder.
\newblock 2019.

\bibitem{10.3390/bioengineering10101209}
M.~Sidulova.
\newblock Conditional variational autoencoder for functional connectivity analysis of autism spectrum disorder functional magnetic resonance imaging data: a comparative study.
\newblock {\em Bioengineering}, 10:1209, 2023.

\bibitem{10.48550/arxiv.2106.06500}
X.~Bie, L.~Girin, S.~Leglaive, T.~Hueber, and X.~Alameda-Pineda.
\newblock A benchmark of dynamical variational autoencoders applied to speech spectrogram modeling.
\newblock 2021.

\bibitem{10.21437/interspeech.2016-1295}
B.~Damavandi, S.~Kumar, N.~Shazeer, and A.~Bruguier.
\newblock Nn-grams: unifying neural network and n-gram language models for speech recognition.
\newblock 2016.

\bibitem{10.1609/aaai.v32i1.11967}
F.~Liza and M.~Grzes.
\newblock Improving language modelling with noise contrastive estimation.
\newblock {\em Proceedings of the Aaai Conference on Artificial Intelligence}, 32, 2018.

\bibitem{10.18653/v1/e17-2003}
M.~Labeau and A.~Allauzen.
\newblock An experimental analysis of noise-contrastive estimation: the noise distribution matters.
\newblock 2017.

\bibitem{10.48550/arxiv.1805.07516}
T.~Matsuda and A.~Hyvärinen.
\newblock Estimation of non-normalized mixture models and clustering using deep representation.
\newblock 2018.

\bibitem{10.48550/arxiv.2205.01789}
P.~Awasthi, N.~Dikkala, and P.~Kamath.
\newblock Do more negative samples necessarily hurt in contrastive learning?
\newblock 2022.

\bibitem{10.1109/cvpr42600.2020.00754}
R.~Gao, E.~Nijkamp, D.~Kingma, Z.~Xu, A.~Dai, and Y.~Wu.
\newblock Flow contrastive estimation of energy-based models.
\newblock 2020.

\bibitem{10.18653/v1/p16-1186}
W.~Chen, D.~Grangier, and M.~Auli.
\newblock Strategies for training large vocabulary neural language models.
\newblock 2016.

\bibitem{10.3115/v1/n15-1083}
P.~Baltescu and P.~Blunsom.
\newblock Pragmatic neural language modelling in machine translation.
\newblock 2015.

\bibitem{10.48550/arxiv.2203.01110}
O.~Chehab, A.~Gramfort, and A.~Hyvärinen.
\newblock The optimal noise in noise-contrastive learning is not what you think.
\newblock 2022.

\bibitem{10.1145/2640087.2644155}
M.~Li.
\newblock Scaling distributed machine learning with the parameter server.
\newblock 2014.

\bibitem{10.3389/fnhum.2015.00505}
F.~Lecaignard, O.~Bertrand, G.~Gimenez, J.~Mattout, and A.~Caclin.
\newblock Implicit learning of predictable sound sequences modulates human brain responses at different levels of the auditory hierarchy.
\newblock {\em Frontiers in Human Neuroscience}, 9, 2015.

\bibitem{10.1186/1471-2105-16-s16-s2}
H.~Liu, K.~Verspoor, D.~Comeau, A.~MacKinlay, and W.~Wilbur.
\newblock Optimizing graph-based patterns to extract biomedical events from the literature.
\newblock {\em BMC Bioinformatics}, 16, 2015.

\bibitem{10.1007/978-1-4615-5339-7_102}
B.~Wang, J.~Basart, and J.~Moulder.
\newblock Linear and nonlinear image restoration methods for eddy current nondestructive evaluation.
\newblock pages 791--798, 1998.

\bibitem{10.1007/s10928-021-09787-4}
J.~Parikh, T.~Rumbell, X.~Butova, T.~Myachina, J.~Acero, S.~Khamzin, O.~Solovyova, J.~Kozloski, A.~Khokhlova, and V.~Gurev.
\newblock Generative adversarial networks for construction of virtual populations of mechanistic models: simulations to study omecamtiv mecarbil action.
\newblock {\em Journal of Pharmacokinetics and Pharmacodynamics}, 49:51--64, 2021.

\bibitem{10.1109/taslp.2017.2761547}
Y.~Saito, S.~Takamichi, and H.~Saruwatari.
\newblock Statistical parametric speech synthesis incorporating generative adversarial networks.
\newblock {\em Ieee/Acm Transactions on Audio Speech and Language Processing}, 26:84--96, 2018.

\bibitem{10.48550/arxiv.1802.05637}
T.~Miyato.
\newblock Cgans with projection discriminator.
\newblock 2018.

\bibitem{10.1007/s11263-019-01265-2}
G.~Qi.
\newblock Loss-sensitive generative adversarial networks on lipschitz densities.
\newblock {\em International Journal of Computer Vision}, 128:1118--1140, 2019.

\bibitem{10.1109/tpami.2018.2872043}
X.~Mao, Q.~Li, H.~Xie, R.~Y.~K. Lau, Z.~Wang, and S.~P. Smolley.
\newblock On the effectiveness of least squares generative adversarial networks.
\newblock {\em IEEE Transactions on Pattern Analysis and Machine Intelligence}, 41:2947--2960, 2019.

\bibitem{goodfellow2014generative}
Ian~J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock 2014.

\bibitem{10.48550/arxiv.2203.06026}
T.~Kynkäänniemi, T.~Karras, M.~Aittala, T.~Aila, and J.~Lehtinen.
\newblock The role of imagenet classes in fréchet inception distance.
\newblock 2022.

\bibitem{10.3390/app12157599}
Y.~Xu, T.~Wu, J.~Charlton, and K.~Bennett.
\newblock Gan training acceleration using fréchet descriptor-based coreset.
\newblock {\em Applied Sciences}, 12:7599, 2022.

\bibitem{10.1117/12.2673366}
R.~Xu, J.~Wang, J.~Liu, F.~Ni, and B.~Cao.
\newblock Thermal infrared face image data enhancement method based on deep learning.
\newblock 2023.

\bibitem{10.48550/arxiv.1703.10717}
D.~Berthelot, T.~Schumm, and L.~Metz.
\newblock Began: boundary equilibrium generative adversarial networks.
\newblock 2017.

\bibitem{10.48550/arxiv.2002.02112}
H.~Hyungrok, T.~Jun, and D.~Kim.
\newblock Unbalanced gans: pre-training the generator of generative adversarial network using variational autoencoder.
\newblock 2020.

\end{thebibliography}
