\begin{thebibliography}{10}

\bibitem{10.48550/arxiv.1704.00028}
I.~Gulrajani, F.~Ahmed, M.~Arjovsky, V.~Dumoulin, and A.~Courville.
\newblock Improved training of wasserstein gans.
\newblock 2017.

\bibitem{10.1002/mgea.30}
Y.~Jiang.
\newblock Applications of generative adversarial networks in materials science.
\newblock {\em Materials Genome Engineering Advances}, 2, 2024.

\bibitem{10.1016/j.media.2019.101552}
Y.~Xin, E.~Walia, and P.~Babyn.
\newblock Generative adversarial network in medical imaging: a review.
\newblock {\em Medical Image Analysis}, 58:101552, 2019.

\bibitem{10.1016/j.artmed.2020.101938}
S.~Kazeminia, C.~Baur, A.~Kuijper, B.~Ginneken, N.~Navab, S.~Albarqouni, and A.~Mukhopadhyay.
\newblock Gans for medical image analysis.
\newblock {\em Artificial Intelligence in Medicine}, 109:101938, 2020.

\bibitem{10.1016/j.neucom.2018.09.013}
M.~Frid-Adar, I.~Diamant, E.~Klang, M.~M. Amitai, J.~Goldberger, and H.~Greenspan.
\newblock Gan-based synthetic medical image augmentation for increased cnn performance in liver lesion classification.
\newblock {\em Neurocomputing}, 321:321--331, 2018.

\bibitem{10.1109/iccv.2019.00453}
R.~Abdal, Y.~Qin, and P.~Wonka.
\newblock Image2stylegan: how to embed images into the stylegan latent space?
\newblock {\em 2019 IEEE/CVF International Conference on Computer Vision (ICCV)}, 2019.

\bibitem{10.48550/arxiv.1711.00658}
L.~Han, Y.~Huang, and T.~Zhang.
\newblock Candidates vs. noises estimation for large multi-class classification problem.
\newblock 2017.

\bibitem{10.48550/arxiv.2110.11271}
B.~Liu, E.~Rosenfeld, P.~Ravikumar, and A.~Risteski.
\newblock Analyzing and improving the optimization landscape of noise-contrastive estimation.
\newblock 2021.

\bibitem{10.18653/v1/e17-2003}
M.~Labeau and A.~Allauzen.
\newblock An experimental analysis of noise-contrastive estimation: the noise distribution matters.
\newblock 2017.

\bibitem{10.21437/interspeech.2016-1295}
B.~Damavandi, S.~Kumar, N.~Shazeer, and A.~Bruguier.
\newblock Nn-grams: unifying neural network and n-gram language models for speech recognition.
\newblock 2016.

\bibitem{10.48550/arxiv.2101.03288}
Y.~Song.
\newblock How to train your energy-based models.
\newblock 2021.

\bibitem{10.1561/2200000056}
D.~Kingma and M.~Welling.
\newblock An introduction to variational autoencoders.
\newblock {\em Foundations and Trends® in Machine Learning}, 12:307--392, 2019.

\bibitem{10.3390/jimaging4020036}
B.~Kiran, D.~Thomas, and R.~Parakkal.
\newblock An overview of deep learning based methods for unsupervised and semi-supervised anomaly detection in videos.
\newblock {\em Journal of Imaging}, 4:36, 2018.

\bibitem{10.1088/2632-2153/ab80b7}
Y.~Varolgunes, T.~Bereau, and J.~Rudzinski.
\newblock Interpretable embeddings from molecular simulations using gaussian mixture variational autoencoders.
\newblock {\em Machine Learning Science and Technology}, 1:015012, 2020.

\bibitem{10.48550/arxiv.2002.10464}
S.~Portillo.
\newblock Dimensionality reduction of sdss spectra with variational autoencoders.
\newblock 2020.

\bibitem{10.1109/access.2020.2977671}
C.~Guo, J.~Zhou, H.~Chen, N.~Ying, J.~Zhang, and D.~Zhou.
\newblock Variational autoencoder with optimizing gaussian mixture model priors.
\newblock {\em Ieee Access}, 8:43992--44005, 2020.

\bibitem{10.48550/arxiv.1909.13062}
P.~Munjal, A.~Paul, and N.~Krishnan.
\newblock Implicit discriminator in variational autoencoder.
\newblock 2019.

\bibitem{10.48550/arxiv.2106.06500}
X.~Bie, L.~Girin, S.~Leglaive, T.~Hueber, and X.~Alameda-Pineda.
\newblock A benchmark of dynamical variational autoencoders applied to speech spectrogram modeling.
\newblock 2021.

\bibitem{10.48550/arxiv.2105.05233}
P.~Dhariwal.
\newblock Diffusion models beat gans on image synthesis.
\newblock 2021.

\bibitem{10.48550/arxiv.2009.09761}
Z.~Kong.
\newblock Diffwave: a versatile diffusion model for audio synthesis.
\newblock 2020.

\bibitem{10.48550/arxiv.2206.05564}
Q.~Zhang, M.~Tao, and Y.~Chen.
\newblock Gddim: generalized denoising diffusion implicit models.
\newblock 2022.

\bibitem{10.48550/arxiv.2201.11972}
S.~Liu, D.~Su, and D.~Yu.
\newblock Diffgan-tts: high-fidelity and efficient text-to-speech with denoising diffusion gans.
\newblock 2022.

\bibitem{10.48550/arxiv.2211.00611}
J.~Wu, H.~Fang, Y.~Yang, and Y.~Xu.
\newblock Medsegdiff: medical image segmentation with diffusion probabilistic model.
\newblock 2022.

\bibitem{10.48550/arxiv.2201.00308}
K.~Pandey, A.~Mukherjee, P.~Rai, and A.~Kumar.
\newblock Diffusevae: efficient, controllable and high-fidelity generation from low-dimensional latents.
\newblock 2022.

\bibitem{10.1109/access.2023.3272032}
M.~Fathallah, M.~Sakr, and S.~El-etriby.
\newblock Stabilizing and improving training of generative adversarial networks through identity blocks and modified loss function.
\newblock {\em Ieee Access}, 11:43276--43285, 2023.

\bibitem{10.1049/ipr2.12487}
J.~Mu, C.~Chen, W.~Zhu, S.~Li, and Y.~Zhou.
\newblock Taming mode collapse in generative adversarial networks using cooperative realness discriminators.
\newblock {\em Iet Image Processing}, 16:2240--2262, 2022.

\bibitem{10.3390/e25121657}
Y.~Zou.
\newblock Auto-encoding generative adversarial networks towards mode collapse reduction and feature representation enhancement.
\newblock {\em Entropy}, 25:1657, 2023.

\bibitem{10.1117/1.jei.32.4.043029}
Y.~Gong, Z.~Ming, J.~Yang, M.~Xie, and X.~Ma.
\newblock Distribution constraining for combating mode collapse in generative adversarial networks.
\newblock {\em Journal of Electronic Imaging}, 32, 2023.

\bibitem{10.48550/arxiv.1910.04302}
A.~Dieng.
\newblock Prescribed generative adversarial networks.
\newblock 2019.

\bibitem{10.48550/arxiv.2207.01561}
J.~Dubinski, K.~Deja, S.~Wenzel, P.~Rokita, and T.~Trzciński.
\newblock Selectively increasing the diversity of gan-generated samples.
\newblock 2022.

\bibitem{10.1111/rssb.12476}
Y.~Chen, Q.~Gao, and W.~Xiao.
\newblock Inferential wasserstein generative adversarial networks.
\newblock {\em Journal of the Royal Statistical Society Series B (Statistical Methodology)}, 84:83--113, 2021.

\bibitem{10.54254/2755-2721/18/20230984}
H.~Zhu.
\newblock Comparison of deep convolutional gan and progressive gan for facial image generation.
\newblock {\em Applied and Computational Engineering}, 18:165--171, 2023.

\bibitem{10.3390/e22091055}
H.~Zhao, T.~Li, Y.~Xiao, and Y.~Wang.
\newblock Improving multi-agent generative adversarial nets with variational latent representation.
\newblock {\em Entropy}, 22:1055, 2020.

\bibitem{10.48550/arxiv.2207.12598}
J.~Ho and T.~Salimans.
\newblock Classifier-free diffusion guidance.
\newblock 2022.

\bibitem{10.48550/arxiv.2010.02502}
J.~Song, C.~Meng, and S.~Ermon.
\newblock Denoising diffusion implicit models.
\newblock 2020.

\bibitem{10.48550/arxiv.2111.15640}
K.~Preechakul, N.~Chatthee, S.~Wizadwongsa, and S.~Suwajanakorn.
\newblock Diffusion autoencoders: toward a meaningful and decodable representation.
\newblock 2021.

\bibitem{10.48550/arxiv.2101.02388}
E.~Luhman.
\newblock Knowledge distillation in iterative generative models for improved sampling speed.
\newblock 2021.

\bibitem{10.1109/msp.2017.2765202}
A.~Creswell, T.~White, V.~Dumoulin, K.~Arulkumaran, B.~Sengupta, and A.~A. Bharath.
\newblock Generative adversarial networks: an overview.
\newblock {\em IEEE Signal Processing Magazine}, 35:53--65, 2018.

\bibitem{10.1145/3422622}
I.~Goodfellow, J.~Pouget-Abadie, M.~Mirza, B.~Xu, D.~Warde-Farley, S.~Ozair, A.~Courville, and Y.~Bengio.
\newblock Generative adversarial networks.
\newblock {\em Communications of the Acm}, 63:139--144, 2020.

\bibitem{10.48550/arxiv.2211.07804}
A.~Kazerouni, E.~Aghdam, M.~Heidari, R.~Azad, M.~Fayyaz, I.~Hacihaliloglu, and D.~Merhof.
\newblock Diffusion models for medical image analysis: a comprehensive survey.
\newblock 2022.

\bibitem{10.48550/arxiv.2011.13456}
Y.~Song.
\newblock Score-based generative modeling through stochastic differential equations.
\newblock 2020.

\bibitem{10.1109/cvpr52688.2022.01117}
A.~Lugmayr, M.~Danelljan, A.~Romero, F.~Yu, R.~Timofte, and L.~Gool.
\newblock Repaint: inpainting using denoising diffusion probabilistic models.
\newblock 2022.

\bibitem{10.1109/taslp.2017.2761547}
Y.~Saito, S.~Takamichi, and H.~Saruwatari.
\newblock Statistical parametric speech synthesis incorporating generative adversarial networks.
\newblock {\em Ieee/Acm Transactions on Audio Speech and Language Processing}, 26:84--96, 2018.

\bibitem{10.1007/s10928-021-09787-4}
J.~Parikh, T.~Rumbell, X.~Butova, T.~Myachina, J.~Acero, S.~Khamzin, O.~Solovyova, J.~Kozloski, A.~Khokhlova, and V.~Gurev.
\newblock Generative adversarial networks for construction of virtual populations of mechanistic models: simulations to study omecamtiv mecarbil action.
\newblock {\em Journal of Pharmacokinetics and Pharmacodynamics}, 49:51--64, 2021.

\bibitem{10.48550/arxiv.1802.05637}
T.~Miyato.
\newblock Cgans with projection discriminator.
\newblock 2018.

\bibitem{goodfellow2014generative}
Ian~J. Goodfellow, Jean Pouget-Abadie, Mehdi Mirza, Bing Xu, David Warde-Farley, Sherjil Ozair, Aaron Courville, and Yoshua Bengio.
\newblock Generative adversarial networks.
\newblock 2014.

\bibitem{10.48550/arxiv.2203.06026}
T.~Kynkäänniemi, T.~Karras, M.~Aittala, T.~Aila, and J.~Lehtinen.
\newblock The role of imagenet classes in fréchet inception distance.
\newblock 2022.

\bibitem{10.3390/app12157599}
Y.~Xu, T.~Wu, J.~Charlton, and K.~Bennett.
\newblock Gan training acceleration using fréchet descriptor-based coreset.
\newblock {\em Applied Sciences}, 12:7599, 2022.

\bibitem{10.1117/12.2673366}
R.~Xu, J.~Wang, J.~Liu, F.~Ni, and B.~Cao.
\newblock Thermal infrared face image data enhancement method based on deep learning.
\newblock 2023.

\bibitem{10.48550/arxiv.1703.10717}
D.~Berthelot, T.~Schumm, and L.~Metz.
\newblock Began: boundary equilibrium generative adversarial networks.
\newblock 2017.

\bibitem{10.48550/arxiv.2002.02112}
H.~Hyungrok, T.~Jun, and D.~Kim.
\newblock Unbalanced gans: pre-training the generator of generative adversarial network using variational autoencoder.
\newblock 2020.

\end{thebibliography}
